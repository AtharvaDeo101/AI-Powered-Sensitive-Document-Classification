{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       File Name Predicted Sensitivity\n",
      "9     bank_statement_2027_5.xlsx             Sensitive\n",
      "16     bank_statement_2023_9.pdf             Sensitive\n",
      "18    bank_statement_2029_10.jpg             Sensitive\n",
      "84    bank_statement_2020_2.xlsx             Sensitive\n",
      "128    bank_statement_2024_3.txt             Sensitive\n",
      "133    bank_statement_2025_1.txt             Sensitive\n",
      "137    bank_statement_2028_1.jpg             Sensitive\n",
      "154  bank_statement_2020_12.docx             Sensitive\n",
      "160   bank_statement_2029_12.jpg             Sensitive\n",
      "175   bank_statement_2022_2.xlsx             Sensitive\n",
      "187    bank_statement_2020_8.jpg             Sensitive\n",
      "234   bank_statement_2030_1.docx             Sensitive\n",
      "265    bank_statement_2026_5.jpg             Sensitive\n",
      "269    bank_statement_2029_7.pdf             Sensitive\n",
      "282   bank_statement_2026_11.txt             Sensitive\n",
      "329    bank_statement_2020_3.txt             Sensitive\n",
      "347  bank_statement_2024_10.xlsx             Sensitive\n",
      "349    bank_statement_2021_9.pdf             Sensitive\n",
      "372   bank_statement_2022_11.txt             Sensitive\n",
      "382    bank_statement_2027_2.jpg             Sensitive\n",
      "394   bank_statement_2024_8.xlsx             Sensitive\n",
      "395    bank_statement_2020_3.txt             Sensitive\n",
      "406   bank_statement_2029_9.docx             Sensitive\n",
      "447   bank_statement_2021_4.docx             Sensitive\n",
      "459    bank_statement_2025_8.txt             Sensitive\n",
      "505    bank_statement_2027_2.txt             Sensitive\n",
      "510   bank_statement_2027_11.txt             Sensitive\n",
      "511    bank_statement_2022_2.pdf             Sensitive\n",
      "556    bank_statement_2030_5.pdf             Sensitive\n",
      "557    bank_statement_2028_7.pdf             Sensitive\n",
      "582   bank_statement_2027_11.txt             Sensitive\n",
      "583    bank_statement_2021_8.pdf             Sensitive\n",
      "586    bank_statement_2027_6.pdf             Sensitive\n",
      "593    bank_statement_2023_6.jpg             Sensitive\n",
      "604  bank_statement_2021_12.xlsx             Sensitive\n",
      "609    bank_statement_2025_4.pdf             Sensitive\n",
      "616   bank_statement_2029_11.jpg             Sensitive\n",
      "629   bank_statement_2029_4.xlsx             Sensitive\n",
      "646   bank_statement_2025_12.txt             Sensitive\n",
      "652   bank_statement_2026_10.jpg             Sensitive\n",
      "669   bank_statement_2020_8.xlsx             Sensitive\n",
      "709    bank_statement_2024_6.jpg             Sensitive\n",
      "712   bank_statement_2027_2.xlsx             Sensitive\n",
      "747   bank_statement_2022_3.docx             Sensitive\n",
      "750  bank_statement_2027_11.docx             Sensitive\n",
      "768    bank_statement_2028_1.txt             Sensitive\n",
      "800    bank_statement_2020_5.pdf             Sensitive\n",
      "809    bank_statement_2024_8.pdf             Sensitive\n",
      "815   bank_statement_2024_11.jpg             Sensitive\n",
      "884   bank_statement_2021_10.pdf             Sensitive\n",
      "913    bank_statement_2021_9.jpg             Sensitive\n",
      "963    bank_statement_2021_6.pdf             Sensitive\n",
      "982    bank_statement_2030_9.pdf             Sensitive\n",
      "986  bank_statement_2022_11.docx             Sensitive\n",
      "999    bank_statement_2028_6.jpg             Sensitive\n",
      "Model Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       147\n",
      "           1       1.00      1.00      1.00        53\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"new_metadata.csv\")\n",
    "\n",
    "# Feature Engineering\n",
    "def extract_features(df):\n",
    "    sensitive_files = df[df['File Name'].str.lower().str.contains(\"bank\", na=False)]\n",
    "    print(sensitive_files[['File Name', 'Predicted Sensitivity']])\n",
    "    # Extract file extension from File Type (already in uppercase)\n",
    "    df['File Type'] = df['File Type'].apply(lambda x: x.lower())\n",
    "\n",
    "    # Check for sensitive keywords in the file path\n",
    "    sensitive_keywords = [\"payroll\", \"tax\", \"insurance\", \"contract\", \"agreement\", \"aadhar\", \"bank\"]\n",
    "    df['Path Contains Sensitive Keyword'] = df['File Path'].apply(\n",
    "        lambda path: 1 if any(keyword in path.lower() for keyword in sensitive_keywords) else 0\n",
    "    )\n",
    "    df['Name Contains Sensitive Keyword'] = df['File Name'].apply(\n",
    "        lambda name: 1 if any(keyword in name.lower() for keyword in sensitive_keywords) else 0\n",
    "    )\n",
    "\n",
    "    # Encode the target variable (Predicted Sensitivity)\n",
    "    le = LabelEncoder()\n",
    "    df['Predicted Sensitivity'] = le.fit_transform(df['Predicted Sensitivity'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply feature extraction to the dataset\n",
    "df = extract_features(df)\n",
    "\n",
    "# Select Features (X) and Target (y)\n",
    "X = df[['File Type', 'File Size (Bytes)', 'Path Contains Sensitive Keyword','Name Contains Sensitive Keyword']]\n",
    "y = df['Predicted Sensitivity']\n",
    "\n",
    "# One-hot encode 'File Type'\n",
    "X = pd.get_dummies(X, columns=['File Type'], drop_first=True)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Example function to predict sensitivity of a given file path\n",
    "def predict_sensitivity(file_path):\n",
    "    # Handle backslashes in Windows paths by converting them to forward slashes\n",
    "    file_path = file_path.replace(\"\\\\\", \"/\")\n",
    "    \n",
    "    # Extract file extension (e.g., '.pdf' or '.xlsx')\n",
    "    file_name = file_path.split('/')[-1].lower()\n",
    "    file_extension = file_path.split('.')[-1].lower()\n",
    "    \n",
    "    # Assuming that we have a mapping of file extensions to one-hot encoded values\n",
    "    file_types = ['pdf', 'xlsx', 'docx', 'jpg', 'txt']  # List of file types from training data\n",
    "    file_type_encoded = {f\"File Type_{ft}\": 0 for ft in file_types}  # Initialize all to 0\n",
    "    \n",
    "    if file_extension in file_types:\n",
    "        file_type_encoded[f\"File Type_{file_extension}\"] = 1  # Set the corresponding file type to 1\n",
    "    \n",
    "    # Extract the feature for the given file path (check for sensitive keywords)\n",
    "    sensitive_keywords = [\"payroll\", \"tax\", \"insurance\", \"contract\", \"agreement\", \"aadhar\", \"bank\"]\n",
    "    path_sensitive_keyword = 1 if any(keyword in file_path.lower() for keyword in sensitive_keywords) else 0\n",
    "    name_sensitive_keyword = 1 if any(keyword in file_name.lower() for keyword in sensitive_keywords) else 0\n",
    "\n",
    "    # Dynamically calculate the file size (in bytes)\n",
    "    try:\n",
    "        file_size = os.path.getsize(file_path)  # Get the actual file size\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return \"Non-Sensitive\"  # Default to non-sensitive if file is not found\n",
    "    \n",
    "    # Prepare the input data for prediction (file type, file size, and sensitive keyword check)\n",
    "    input_data = pd.DataFrame({\n",
    "        'File Size (Bytes)': [file_size],\n",
    "        'Path Contains Sensitive Keyword': [path_sensitive_keyword],\n",
    "        'Name Contains Sensitive Keyword': [name_sensitive_keyword],\n",
    "\n",
    "        **file_type_encoded  # Add the one-hot encoded file type columns\n",
    "    })\n",
    "    \n",
    "    # Ensure the input data has the same columns as the training data\n",
    "    # Reorder and add missing columns with default value 0\n",
    "    input_data = input_data.reindex(columns=X_train.columns, fill_value=0)\n",
    "    \n",
    "    # Make prediction\n",
    "    sensitivity_prediction = model.predict(input_data)\n",
    "    if sensitivity_prediction[0] == 1:\n",
    "        return \"Sensitive \"\n",
    "    else: \n",
    "        return\"Non-Sensitive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sensitivity for file: Sensitive \n"
     ]
    }
   ],
   "source": [
    "# Test the prediction function with a Windows-style file path\n",
    "test_file_path = r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\bank.docx\"\n",
    "print(\"Predicted Sensitivity for file:\", predict_sensitivity(test_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the model to disk\n",
    "filename = 'model.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
